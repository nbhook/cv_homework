# åŸºäºclipçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²æ¨¡å‹ç»“æ„å¯¹æ¯”


æœ¬é¡¹ç›®å¯¹æ¯”åˆ†æäº†ä¸‰ä¸ªåŸºäº CLIP çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼š

1. [**OVSeg**](https://github.com/facebookresearch/ov-seg)ï¼šé€šè¿‡è®­ç»ƒè§†è§‰ prompt é€‚é… CLIP åˆ°è¢«é®æŒ¡å›¾åƒä¸Š  
2. [**Side Adapter Network (SAN)**](https://github.com/MendelXu/SAN)ï¼šåœ¨ä¸ä¿®æ”¹ CLIP ä¸»å¹²çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥æ—è·¯ç»“æ„æä¾›ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›  
3. [**CLIP as RNN (CaR)**](https://github.com/google-research/google-research/tree/master/clip_as_rnn)ï¼šä½¿ç”¨è§†è§‰æç¤º + é€’å½’æ¨ç†æ–¹å¼ï¼Œå¼•å¯¼ CLIP é€æ­¥å®Œæˆåˆ†å‰²ä»»åŠ¡

æˆ‘ä»¬å¯¹è¿™ä¸‰ç§æ–¹æ³•çš„ç»“æ„å·®å¼‚ä¸æ¨ç†æµç¨‹è¿›è¡Œäº†åˆ†æï¼Œå¹¶ä¿®æ”¹äº†éƒ¨åˆ†ç”±äºåŒ…ç‰ˆæœ¬æ›´æ–°å¯¼è‡´çš„é—®é¢˜ï¼Œä¾¿äºè¿è¡Œæµ‹è¯•ä¸å¯¹æ¯”ã€‚



---

## ğŸš€ æ¨¡å‹ä½¿ç”¨è¯´æ˜

### 1ï¸âƒ£ OVSeg æ¨¡å‹è¿è¡Œ

- **è¿è¡Œ Demo ç¤ºä¾‹**
```bash
cd ov-seg-main
python demo.py \
  --config-file configs/ovseg_swinB_vitL_demo.yaml \
  --class-names 'Oculus' 'Ukulele' \
  --input ./resources/demo_samples/sample_03.jpeg \
  --output ./pred \
  --opts MODEL.WEIGHTS path/to/your/weight.pth
```

---

### 2ï¸âƒ£ SAN æ¨¡å‹è¿è¡Œ

- **å®‰è£…ä¾èµ–**
```bash
git clone https://github.com/MendelXu/SAN.git
cd SAN
bash install.sh
```

- **ä½¿ç”¨ Docker è¿è¡Œ Demo**
```bash
docker build docker/app.Docker -t san_app
docker run -it --shm-size 4G -p 7860:7860 san_app
```

- **è®­ç»ƒæ¨¡å‹**
```bash
cd SAN
python train_net.py \
  --config-file configs/san_clip_vit_res4_coco.yaml \
  --num-gpus 1 \
  OUTPUT_DIR ./output/san_vit_b16
```

- **è¯„ä¼°æ¨¡å‹**
```bash
python train_net.py --eval-only \
  --config-file configs/san_clip_vit_res4_coco.yaml \
  --num-gpus 1 \
  OUTPUT_DIR ./output/san_vit_b16_eval \
  MODEL.WEIGHTS output/san_vit_b_16.pth \
  DATASETS.TEST "('ade20k_sem_seg_val',)"
```

- **å¯è§†åŒ–åˆ†å‰²ç»“æœ**
```bash
python visualize_json_results.py \
  --input output/san_vit_b16_eval/inference/sem_seg_predictions.json \
  --output output/san_vit_b16_eval/viz \
  --dataset ade20k_sem_seg_val
```

---

### 3ï¸âƒ£ CLIP as RNN æ¨¡å‹è¿è¡Œ

- **è¿è¡Œå•å¼ å›¾åƒæµ‹è¯•**
```bash
cd clip_as_rnn
python3 demo.py \
  --cfg-path=configs/ade20k/car_vitb_clip.yaml \
  --output_path=results/demo
```

- **åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹**
```bash
python3 evaluate.py --cfg-path=configs/ade20k/car_vitb_clip.yaml
```

---

## ğŸ“š å¼•ç”¨ä¿¡æ¯Citation


```bibtex
@inproceedings{clip_as_rnn,
  title = {CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor},
  author = {Sun, Shuyang and Li, Runjia and Torr, Philip and Gu, Xiuye and Li, Siyang},
  year = {2024},
  booktitle = {CVPR},
}

@article{xu2023san,
  title={SAN: Side adapter network for open-vocabulary semantic segmentation},
  author={Xu, Mengde and Zhang, Zheng and Wei, Fangyun and Hu, Han and Bai, Xiang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{xu2023side,
  title={Side Adapter Network for Open-Vocabulary Semantic Segmentation},
  author={Mengde Xu, Zheng Zhang, Fangyun Wei, Han Hu, Xiang Bai},
  journal={CVPR},
  year={2023}
}

@inproceedings{liang2023open,
  title={Open-vocabulary semantic segmentation with mask-adapted clip},
  author={Liang, Feng and Wu, Bichen and Dai, Xiaoliang and Li, Kunpeng and Zhao, Yinan and Zhang, Hang and Zhang, Peizhao and Vajda, Peter and Marculescu, Diana},
  booktitle={CVPR},
  pages={7061--7070},
  year={2023}
}
```
